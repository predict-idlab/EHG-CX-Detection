{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:105: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from cx_model import CXDetector\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "import wfdb\n",
    "from scipy.signal import butter, lfilter, medfilt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def _read_signal(file, low_freq, high_freq, sample_freq):\n",
    "    record = wfdb.rdrecord(file)\n",
    "    annotation = wfdb.rdann(file, 'atr')\n",
    "    annotated_intervals = list(zip(annotation.sample, annotation.aux_note))\n",
    "    \n",
    "    signal_ch1 = record.p_signal[:, 0][1500:-1500]\n",
    "    signal_ch2 = record.p_signal[:, 2][1500:-1500]\n",
    "    signal_ch3 = record.p_signal[:, 4][1500:-1500]\n",
    "    \n",
    "    signal_ch1 = butter_bandpass_filter(signal_ch1, low_freq, \n",
    "                                        high_freq, sample_freq, order=4)\n",
    "    signal_ch2 = butter_bandpass_filter(signal_ch2, low_freq, \n",
    "                                        high_freq, sample_freq, order=4)\n",
    "    signal_ch3 = butter_bandpass_filter(signal_ch3, low_freq, \n",
    "                                        high_freq, sample_freq, order=4)\n",
    "    \n",
    "    for i, ann in enumerate(annotated_intervals):\n",
    "        annotated_intervals[i] = (ann[0] - 1500, ann[1]) \n",
    "\n",
    "    signal_ch1 = medfilt(signal_ch1)\n",
    "    signal_ch2 = medfilt(signal_ch2)\n",
    "    signal_ch3 = medfilt(signal_ch3)\n",
    "\n",
    "    ch1_scaler = RobustScaler()\n",
    "    ch2_scaler = RobustScaler()\n",
    "    ch3_scaler = RobustScaler()\n",
    "\n",
    "    signal_ch1 = ch1_scaler.fit_transform(signal_ch1.reshape(-1, 1)).reshape(-1, )\n",
    "    signal_ch2 = ch2_scaler.fit_transform(signal_ch2.reshape(-1, 1)).reshape(-1, )\n",
    "    signal_ch3 = ch3_scaler.fit_transform(signal_ch3.reshape(-1, 1)).reshape(-1, )\n",
    "        \n",
    "    return signal_ch1, signal_ch2, signal_ch3, annotated_intervals\n",
    "\n",
    "\n",
    "def _read_clinical(file):\n",
    "    start_idx = 0\n",
    "    with open(file+'.hea', 'r') as ifp:\n",
    "        lines = ifp.readlines()\n",
    "        \n",
    "    for line_idx, line in enumerate(lines):\n",
    "        if line.startswith('#'):\n",
    "            start_idx = line_idx\n",
    "            break\n",
    "\n",
    "    names = []\n",
    "    values = []\n",
    "    for line in lines[start_idx+1:]:\n",
    "        _, name, value = line.split()\n",
    "        names.append(name)\n",
    "        values.append(value)\n",
    "\n",
    "    return names, values\n",
    "\n",
    "def _process_clinical_df(clin_df):\n",
    "    clin_df = clin_df.drop(['Gestation'], axis=1)\n",
    "    clin_df = clin_df.replace('None', np.NaN)\n",
    "    clin_df = clin_df.replace('N/A', np.NaN)\n",
    "    clin_df['ID'] = clin_df['RecID']\n",
    "    for col in ['Rectime', 'Age', 'Abortions', 'Weight']:\n",
    "        clin_df[col] = clin_df[col].astype(float)\n",
    "    clin_df = clin_df.drop_duplicates()\n",
    "    clin_df = clin_df[['file', 'Rectime', 'Age', 'Parity', 'Abortions']]\n",
    "    return clin_df\n",
    "\n",
    "\n",
    "def partition_data(directory, n_splits=5):\n",
    "    files = np.unique([x.split('.')[0] for x in os.listdir(directory)])\n",
    "    p_files, t_files, n_files = [], [], []\n",
    "    for file in files:\n",
    "        if file[-4] == 'n':\n",
    "            n_files.append(file)\n",
    "        elif file[-4] == 'p':\n",
    "            p_files.append(file)\n",
    "        else:\n",
    "            t_files.append(file)\n",
    "\n",
    "    np.random.shuffle(p_files)\n",
    "    np.random.shuffle(t_files)\n",
    "\n",
    "    folds = []\n",
    "    for split in range(n_splits):\n",
    "        start = lambda x: int(x * (split / n_splits))\n",
    "        end   = lambda x: int(x * ((split + 1) / n_splits))\n",
    "        if split == n_splits - 1:\n",
    "            test_p_files = p_files[start(len(p_files)):]\n",
    "            test_t_files = t_files[start(len(t_files)):]\n",
    "        else:\n",
    "            test_p_files = p_files[start(len(p_files)):end(len(p_files))]\n",
    "            test_t_files = t_files[start(len(t_files)):end(len(t_files))]\n",
    "\n",
    "        train_p_files = sorted(list(set(p_files) - set(test_p_files)))\n",
    "        train_t_files = sorted(list(set(t_files) - set(test_t_files)))\n",
    "\n",
    "        test_files = test_t_files + test_p_files\n",
    "        train_files = train_t_files + train_p_files\n",
    "\n",
    "        folds.append((['{}{}{}'.format(directory, os.sep, x) for x in train_files], \n",
    "                      ['{}{}{}'.format(directory, os.sep, x) for x in test_files]))\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.029109\n",
      "0:\tlearn: 0.6768448\ttest: 0.6714530\tbest: 0.6714530 (0)\ttotal: 165ms\tremaining: 27m 28s\n",
      "100:\tlearn: 0.1672094\ttest: 0.1533615\tbest: 0.1533615 (100)\ttotal: 8.55s\tremaining: 13m 58s\n",
      "200:\tlearn: 0.0842679\ttest: 0.1413783\tbest: 0.1412323 (199)\ttotal: 15.4s\tremaining: 12m 29s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1401971479\n",
      "bestIteration = 211\n",
      "\n",
      "Shrink model to first 212 iterations.\n"
     ]
    }
   ],
   "source": [
    "folds = partition_data('tpehgts')\n",
    "train_files, test_files = folds[0]\n",
    "detector = CXDetector(20, 0.05, 4.0, 750, 125, 100, 100, _read_signal, _read_clinical, _process_clinical_df)\n",
    "features = detector.fit(train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_labels_preds(intervals, predictions):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for (start_idx, start_type), (end_idx, end_type) in zip(intervals[::2], intervals[1::2]):\n",
    "        if start_idx < 0 or end_idx >= len(predictions):\n",
    "            continue\n",
    "        if start_type[-1] == 'C':\n",
    "            labels.extend([1]*(end_idx - start_idx))\n",
    "            preds.extend(predictions.loc[list(range(start_idx, end_idx)), 'pred'].values)\n",
    "        else:\n",
    "            labels.extend([0]*(end_idx - start_idx))\n",
    "            preds.extend(predictions.loc[list(range(start_idx, end_idx)), 'pred'].values)\n",
    "\n",
    "    return labels, preds\n",
    "\n",
    "def _load_pred_labels_intervals(predictions):\n",
    "    _, _, _, intervals = _read_signal(predictions['file'].values[0], 0.05, 4.0, 20.0)\n",
    "    labels, preds = get_labels_preds(intervals, predictions)\n",
    "    return labels, preds, intervals\n",
    "\n",
    "def unweighted_auc(predictions):\n",
    "    all_labels, all_preds = [], []\n",
    "    for file in np.unique(predictions['file']):\n",
    "        preds = predictions[predictions['file'] == file].set_index('index', drop=True)\n",
    "        labels, preds, intervals = _load_pred_labels_intervals(preds)\n",
    "        all_labels.extend(labels)\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "    mask = ~np.isnan(all_preds)\n",
    "    return roc_auc_score(np.array(all_labels)[mask], np.array(all_preds)[mask])\n",
    "\n",
    "def create_plots(predictions):\n",
    "    def create_plot(signal_ch1, signal_ch2, signal_ch3, predictions, intervals):\n",
    "        f, ax = plt.subplots(4, 1, sharex=True, figsize=(15,3))\n",
    "        ax[0].plot(signal_ch1)\n",
    "        ax[1].plot(signal_ch2)\n",
    "        ax[2].plot(signal_ch3)\n",
    "\n",
    "        _max = np.max([np.max(signal_ch1), np.max(signal_ch2), np.max(signal_ch3)])\n",
    "        _min = np.min([np.min(signal_ch1), np.min(signal_ch2), np.min(signal_ch3)])\n",
    "\n",
    "        for (start_idx, start_type), (end_idx, end_type) in zip(intervals[::2], intervals[1::2]):\n",
    "            if start_type[-1] == 'C':\n",
    "                color = 'g'\n",
    "            elif start_type == '(c)':\n",
    "                color = 'y'\n",
    "            else:\n",
    "                color = 'r'\n",
    "\n",
    "            for k in range(3):\n",
    "                rect = patches.Rectangle((start_idx, _min), end_idx - start_idx, _max - _min, facecolor=color, alpha=0.5)\n",
    "                ax[k].add_patch(rect)\n",
    "\n",
    "        ax[3].plot(predictions)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    for file in np.unique(predictions['file']):\n",
    "        sign_ch1, sign_ch2, sign_ch3, intervals = _read_signal(file, 0.05, 4.0, 20.0)\n",
    "        create_plot(sign_ch1, sign_ch2, sign_ch3, predictions[predictions['file'] == file]['pred'].values, intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = detector.predict(test_files)\n",
    "print(unweighted_auc(preds))\n",
    "create_plots(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
